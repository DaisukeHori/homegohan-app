#!/usr/bin/env node

/**
 * åŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«å†ç”Ÿæˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ
 * text-embedding-3-large (1536æ¬¡å…ƒ) ã§å…¨ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’æ›´æ–°
 */

import { config } from "dotenv";
import { createClient } from "@supabase/supabase-js";
import OpenAI from "openai";

// .env.local ã‚’èª­ã¿è¾¼ã‚€
config({ path: ".env.local" });

const SUPABASE_URL = process.env.SUPABASE_URL || process.env.NEXT_PUBLIC_SUPABASE_URL;
const SUPABASE_SERVICE_KEY = process.env.SUPABASE_SERVICE_ROLE_KEY;
const OPENAI_API_KEY = process.env.OPENAI_API_KEY;

if (!SUPABASE_URL || !SUPABASE_SERVICE_KEY || !OPENAI_API_KEY) {
  console.error("Missing environment variables");
  process.exit(1);
}

const supabase = createClient(SUPABASE_URL, SUPABASE_SERVICE_KEY);
const openai = new OpenAI({ apiKey: OPENAI_API_KEY });

const BATCH_SIZE = 100;
const DIMENSIONS = 1536;
const MODEL = "text-embedding-3-large";

async function embedBatch(texts) {
  const response = await openai.embeddings.create({
    model: MODEL,
    input: texts,
    dimensions: DIMENSIONS,
  });
  return response.data.map((d) => d.embedding);
}

async function processTable(tableName, textColumn, embeddingColumn) {
  console.log(`\nğŸ“Š Processing ${tableName}...`);

  // ã‚«ã‚¦ãƒ³ãƒˆå–å¾—
  const { count } = await supabase
    .from(tableName)
    .select("*", { count: "exact", head: true });

  console.log(`   Total rows: ${count}`);

  let processed = 0;
  let offset = 0;

  while (offset < count) {
    // ãƒãƒƒãƒå–å¾—
    const { data: rows, error } = await supabase
      .from(tableName)
      .select(`id, ${textColumn}`)
      .range(offset, offset + BATCH_SIZE - 1);

    if (error) {
      console.error(`   Error fetching rows:`, error.message);
      break;
    }

    if (!rows || rows.length === 0) break;

    // ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡º
    const texts = rows.map((r) => r[textColumn] || "");
    
    // åŸ‹ã‚è¾¼ã¿ç”Ÿæˆ
    const embeddings = await embedBatch(texts);

    // æ›´æ–°
    for (let i = 0; i < rows.length; i++) {
      const { error: updateError } = await supabase
        .from(tableName)
        .update({ [embeddingColumn]: embeddings[i] })
        .eq("id", rows[i].id);

      if (updateError) {
        console.error(`   Error updating row ${rows[i].id}:`, updateError.message);
      }
    }

    processed += rows.length;
    offset += BATCH_SIZE;

    const pct = ((processed / count) * 100).toFixed(1);
    process.stdout.write(`\r   Progress: ${processed}/${count} (${pct}%)`);
  }

  console.log(`\n   âœ… Completed ${tableName}`);
}

async function main() {
  console.log("ğŸš€ Starting embedding regeneration");
  console.log(`   Model: ${MODEL}`);
  console.log(`   Dimensions: ${DIMENSIONS}`);

  const startTime = Date.now();

  // 1. dataset_ingredients
  await processTable("dataset_ingredients", "name", "name_embedding");

  // 2. dataset_recipes
  await processTable("dataset_recipes", "name", "name_embedding");

  // 3. dataset_menu_sets (content ã‚«ãƒ©ãƒ ã‚’ä½¿ç”¨)
  await processTable("dataset_menu_sets", "content", "content_embedding");

  const elapsed = ((Date.now() - startTime) / 1000 / 60).toFixed(1);
  console.log(`\nğŸ‰ All done! Total time: ${elapsed} minutes`);
}

main().catch(console.error);
